version: '3.3'
services:
  tritonserver:
    ports:
      - '8000:8000'
      - '8001:8001'
      - '8002:8002'
    volumes:
      - 'D:/E/Copy/PyCharm/Hometask/ml_hard_models_2025/hw3/model_repository:/models'
      - 'D:/E/Copy/PyCharm/Hometask/ml_hard_models_2025/hw3/envs:/envs'
    container_name: 'HSE_ht3-triton'
    image: nvcr.io/nvidia/tritonserver:25.01-py3
    # user: root
    command: sh -c "pip install --no-cache-dir numpy pillow && tritonserver --id=hse-ht3-triton --model-repository=/models --exit-on-error=false --repository-poll-secs=60 --allow-metrics=true --allow-cpu-metrics=true"
    shm_size: '16gb'
    stdin_open: true
